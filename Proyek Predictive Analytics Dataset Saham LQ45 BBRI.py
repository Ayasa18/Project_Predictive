# -*- coding: utf-8 -*-
"""SubmissionPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iXjeFCKWmFzsyH5XwI_QwMzeQl1BIvC3

# Proyek Predictive Analytics: [Dataset Saham LQ45 BBRI]
- **Nama:** [Aditiya Saputra]
- **Email:** [AditiyaS1811@gmail.com]
- **ID Dicoding:** [aditiya18]

Source Dataset : https://github.com/wildangunawan/Dataset-Saham-IDX/blob/master/Saham/LQ45/BBRI.csv

##Deskripsi Proyek

Proyek ini bertujuan untuk memprediksi pergerakan harga saham BBRI yang merupakan bagian dari indeks LQ45, dengan menggunakan metode predictive analytics berbasis machine learning. Dataset yang digunakan berisi data historis harga saham BBRI dari indeks LQ45 yang mencakup berbagai faktor seperti harga pembukaan, penutupan, tertinggi, terendah, serta volume perdagangan. Data ini digunakan untuk melatih model yang dapat memprediksi harga saham atau tren pergerakan harga di masa depan.

Langkah-langkah dalam proyek ini:
1.   Persiapan Data:
    *   Dataset saham BBRI diambil dari sumber terpercaya, lalu diproses untuk menangani nilai yang hilang dan memastikan kualitas data yang digunakan.
    *   Normalisasi dilakukan menggunakan MinMaxScaler untuk memastikan bahwa semua fitur berada dalam rentang yang konsisten, yang mempermudah proses pelatihan model.
    *   Split Data menjadi 80:20
2.   Pemodelan:
    *   Model yang digunakan adalah Long Short-Term Memory (LSTM), yang merupakan jenis jaringan saraf tiruan yang sangat efektif dalam memproses data sekuensial atau time series seperti harga saham.
    *   Proses pelatihan dilakukan untuk menemukan pola dalam data historis yang dapat digunakan untuk memprediksi harga saham BBRI di masa depan.
3.   Prediksi dan Visualisasi:
    *   Setelah model terlatih, digunakan untuk memprediksi harga saham BBRI
    *   Visualisasi hasil prediksi dibandingkan dengan harga saham aktual untuk mengevaluasi kinerja model secara visual.
4.   Evaluasi Model:
    *   Model dievaluasi menggunakan berbagai metrik, seperti MSE (Mean Squared Error) dan MAE (Mean Absolute Error), untuk mengukur seberapa akurat prediksi yang dihasilkan oleh model.
    *   Perbandingan dilakukan dengan data validasi untuk menghindari overfitting dan memastikan generalisasi yang baik.

Tujuan Proyek:


*   Mengembangkan model prediktif yang dapat memberikan wawasan tentang kemungkinan pergerakan harga saham BBRI di masa depan.
*   Memberikan dasar yang kuat bagi pengambilan keputusan investasi berdasarkan data historis dan analisis prediktif.

Proyek ini tidak hanya meningkatkan pemahaman tentang penggunaan LSTM dalam analisis keuangan, tetapi juga menguji bagaimana teknik predictive analytics dapat diterapkan pada pasar saham untuk memprediksi tren harga dengan akurasi yang tinggi.

## Import Semua Packages/Library yang Digunakan
"""

###install (Technical Analysis Library di Python)
!pip install ta
import pandas as pd ###manipulasi dan analisis data tabular
import numpy as np ###pengolahan data numerik
import matplotlib.pyplot as plt ###membuat visualisasi, grafik, dan plot data.
import seaborn as sns ### membuat visualisasi data yang lebih menarik dan informatif dengan lebih sedikit kode
import tensorflow as tf ### membangun model jaringan saraf tiruan (neural network) berbasis LSTM (Long Short-Term Memory)
from tensorflow import keras ###pembuatan dan pelatihan model jaringan saraf.
sns.set_style("whitegrid") ###latar belakang plot akan menjadi putih, dan grid akan ditampilkan di belakang plot
plt.style.use("fivethirtyeight") ###visualisasi data yang mirip dengan yang digunakan oleh FiveThirtyEight
from datetime import datetime ###impor fungsi datetime
from sklearn.preprocessing import MinMaxScaler ###import untuk normalisasi data
from keras.models import Sequential  ###import class untuk neural network
from keras.layers import Dense, LSTM ###Import dense untuk melakukan transformasi linier
import ta ###import technical analysis
import warnings ###mengendalikan pesan peringatan (warnings) yang dapat muncul selama eksekusi kode
warnings.filterwarnings("ignore") ###mengabaikan semua pesan peringatan yang mungkin muncul selama eksekusi kode
from datetime import date ###berguna untuk bekerja dengan tanggal dalam Python

"""## Data Preparation

### Data Loading
"""

# URL GitHub untuk file CSV mentah
url = "https://raw.githubusercontent.com/wildangunawan/Dataset-Saham-IDX/master/Saham/LQ45/BBRI.csv"
# Membaca dataset
df = pd.read_csv(url)
# Menampilkan 5 baris pertama
print(df.head())

df.info()  #menampilkan informasi data frame

"""Output dari df.info() menunjukkan bahwa DataFrame terdiri dari 1355 baris dan 25 kolom, yang sebagian besar berisi data bertipe float64 dan satu kolom bertipe object yaitu kolom date. Semua kolom kecuali delisting_date memiliki nilai non-null sebanyak 1355, artinya tidak ada nilai yang hilang di kolom-kolom tersebut. Namun, kolom delisting_date tidak memiliki satu pun nilai yang valid (0 non-null), sehingga kemungkinan besar kolom ini bisa dihapus karena tidak mengandung informasi yang berguna. Secara keseluruhan, informasi ini membantu dalam memahami struktur data, tipe data tiap kolom, dan apakah ada data yang hilang sebelum proses pembersihan atau analisis lebih lanjut."""

df.describe() # menghasilkan statistik deskriptif ringkas dari DataFrame

"""Perintah df.describe() digunakan untuk menghasilkan statistik deskriptif ringkas dari DataFrame, yang mencakup metrik-metrik penting seperti jumlah data (count), nilai rata-rata (mean), standar deviasi (std), nilai minimum (min), nilai kuartil pertama (25%), median (50%), kuartil ketiga (75%), dan nilai maksimum (max) untuk setiap kolom numerik. Statistik ini berguna untuk memahami distribusi, sebaran, serta kecenderungan data secara umum, sehingga dapat membantu dalam proses eksplorasi data, deteksi outlier, dan pengambilan keputusan terkait preprocessing atau pemodelan data."""

df.isnull().sum()

"""Perintah df.isnull().sum() digunakan untuk menghitung jumlah nilai yang hilang (null) di setiap kolom dalam DataFrame. Hasilnya akan menunjukkan berapa banyak data yang kosong pada masing-masing kolom, sehingga memudahkan kita dalam mengidentifikasi dan menangani data yang tidak lengkap, dalam konteks ini delisting_date memiliki 1355 kolom yang kosong atau null

### Data Preprocessing

### Menghapus Kolom yang tidak diperlukan atau memiliki nilai NULL

Dalam prediksi harga saham harian, hanya kolom yang secara langsung mencerminkan aktivitas pasar dan pergerakan harga yang dipertahankan, seperti date, open_price, high, low, close, volume, value, frequency, foreign_sell, dan foreign_buy, karena informasi ini relevan untuk analisis tren, volatilitas, dan sentimen pasar. Sementara itu, kolom seperti previous, first_trade, offer, bid, listed_shares, hingga non_regular_* dihapus karena bersifat redundan, statis, tidak relevan untuk prediksi jangka pendek, atau bahkan mengandung banyak nilai kosong sehingga tidak memberikan kontribusi signifikan pada model.
"""

# Drop kolom yang tidak diperlukan
cols_to_drop = [
    'change',                # fitur turunan dari previous & close
    'index_individual',
    'offer', 'offer_volume',
    'bid', 'bid_volume',
    'listed_shares', 'tradeble_shares',
    'weight_for_index',
    'delisting_date',        # semuanya null
    'non_regular_volume', 'non_regular_value', 'non_regular_frequency'
]

df_cleaned = df.drop(columns=cols_to_drop)

# Tampilkan kolom setelah dibersihkan
print("\nKolom setelah dibersihkan:\n", df_cleaned.columns.tolist())

# Cek info ringkas setelah pembersihan
print("\nInfo dataframe setelah dibersihkan:")
df_cleaned.info()

"""###Memastikan data ke format datetime dan diurutkan berdasarkan waktu.

kolom 'date' dikonversi ke format datetime agar dapat dikenali sebagai tipe data waktu oleh pandas. Setelah itu, data diurutkan berdasarkan tanggal secara menaik (ascending) untuk memastikan urutan kronologisnya benar. Kemudian, kolom 'date' disimpan ke dalam variabel terpisah (dates) agar tidak ikut diproses dalam langkah-langkah seperti normalisasi atau scaling yang hanya berlaku untuk data numerik. Langkah terakhir adalah mencetak beberapa baris awal dari DataFrame (df_cleaned) untuk memastikan perubahan telah diterapkan dengan benar.
"""

# Konversi kolom 'date' ke datetime
df_cleaned['date'] = pd.to_datetime(df_cleaned['date'])

# Urutkan berdasarkan tanggal secara ascending
df_cleaned = df_cleaned.sort_values(by='date').reset_index(drop=True)

# Simpan kolom 'date' ke variabel terpisah agar tidak diskalakan
dates = df_cleaned['date']

# Cek hasilnya
print(df_cleaned.head())

# Hanya kolom numerik yang akan dinormalisasi
features = ['open_price', 'high', 'low', 'close']

# Simpan kolom tanggal (pastikan kolom tanggal sudah ada dan bernama 'date')
dates = df_cleaned[['date']].copy()

# Salin data numerik untuk penskalaan
features_scaled = df_cleaned[features].copy()

# Normalisasi menggunakan MinMaxScaler
MMS = MinMaxScaler()
features_scaled_scaled = MMS.fit_transform(features_scaled)

# Konversi hasil scaling ke DataFrame kembali dengan kolom yang sesuai
features_scaled_df = pd.DataFrame(features_scaled_scaled, columns=features)

# Gabungkan kembali kolom tanggal dengan data yang telah dinormalisasi
df_scaled = pd.concat([dates.reset_index(drop=True), features_scaled_df.reset_index(drop=True)], axis=1)

# Tampilkan 5 data pertama
print(df_scaled.head())

"""Feature Engineering dan melakukan normalisasi pada kolom-kolom numerik tertentu dalam dataset agar nilainya berada dalam rentang yang seragam, biasanya antara 0 dan 1, menggunakan metode MinMaxScaler. Kolom yang dinormalisasi adalah 'open_price', 'high', 'low', dan 'close', yang semuanya berkaitan dengan harga saham. Proses ini dilakukan dengan tetap memisahkan kolom 'date' agar tidak ikut terpengaruh oleh normalisasi. Setelah dinormalisasi, data dikonversi kembali menjadi DataFrame dan digabungkan lagi dengan kolom tanggal, sehingga menghasilkan dataset baru (df_scaled) yang siap digunakan untuk pemodelan atau visualisasi dengan nilai-nilai yang sudah berskala."""

df_scaled.shape # mengetahui dimensi dari DataFrame

#digunakan untuk pelatihan (training size) dalam konteks pembagian data menjadi data pelatihan dan data pengujian (training and testing data) 80%:20%
training_size = round(len(df_scaled) * 0.80)
training_size

"""menentukan ukuran data pelatihan (training set) dengan mengambil 80% dari total jumlah data. Fungsi len(df_scaled) menghitung jumlah total baris, lalu dikalikan 0.80 untuk mendapatkan 80 persennya, dan hasilnya dibulatkan menggunakan round() agar menjadi angka bulat. Nilai ini nantinya akan digunakan untuk memisahkan data menjadi data pelatihan dan data pengujian (testing)."""

#split data
train_data = df_scaled[:training_size] #data train
test_data  = df_scaled[training_size:] #data test

train_data.shape, test_data.shape    #train dan tes tetap berjumlah 4 kolom dari shape

# Split data menjadi train dan test
# ************************************************************************************************

size = 271  # jumlah hari terakhir untuk test data
train_data = df_scaled[:-size].copy()
test_data = df_scaled[-size:].copy()

# Pastikan kolom 'date' menjadi index agar plot berdasarkan waktu
train_data.set_index('date', inplace=True)
test_data.set_index('date', inplace=True)

# Tampilkan rentang tanggal dari train dan test
print(f"Train dates : {train_data.index.min().date()} --- {train_data.index.max().date()}  (n={len(train_data)})")
print(f"Test dates  : {test_data.index.min().date()} --- {test_data.index.max().date()}  (n={len(test_data)})")
print()

# Visualisasi data train dan test
# ************************************************************************************************

col = 'high'  # kolom yang ingin divisualisasikan
plt.figure(figsize=(12, 4))
plt.plot(train_data[col], label='Train')
plt.plot(test_data[col], label='Test')
plt.title(f'Perbandingan Data Train dan Test pada Kolom: {col.upper()}')
plt.xlabel('Tanggal')
plt.ylabel('Harga')
plt.legend()
plt.grid(True)
plt.show()

""" Visualisasi tersebut membantu memahami sejauh mana cakupan data train dan test serta melihat perbandingan tren harga pada kolom tertentu (dalam hal ini kolom 'high') dari waktu ke waktu."""

def create_sequence(dataset):
    """
    Membuat urutan sequence dan label dari dataset time series.

    Args:
    - dataset: DataFrame, data time series yang sudah dinormalisasi (tanpa kolom tanggal)

    Returns:
    - sequences: array berisi urutan data (X)
    - labels: array berisi target/label prediksi (y)
    """
    sequences = []  # untuk menyimpan urutan data input (fitur)
    labels = []     # untuk menyimpan data target (label)

    start_idx = 0  # indeks awal dari urutan data

    # Loop dimulai dari 50 (ukuran jendela/sequence) hingga akhir dataset
    for stop_idx in range(50, len(dataset)):
        sequences.append(dataset.iloc[start_idx:stop_idx].values)
        labels.append(dataset.iloc[stop_idx].values)  # ambil 1 baris sebagai label (biasanya kolom 'close' saja)
        start_idx += 1  # geser jendela ke depan

    return np.array(sequences), np.array(labels)

#membuat urutan data pelatihan (training data) dan pengujian (testing data)
X_train, y_train = create_sequence(train_data)
X_test, y_test = create_sequence(test_data)

X_train.shape, y_train.shape, X_test.shape, y_test.shape # shape memeriksa jumlah baris dan kolom setelah di split

"""## Modelling

Membangun sebuah model deep learning dengan arsitektur Long Short-Term Memory (LSTM) menggunakan Sequential dari Keras, yang dirancang khusus untuk menangani data deret waktu seperti prediksi harga saham. Model ini terdiri dari empat lapisan LSTM berurutan, masing-masing dengan 50 unit neuron; tiga lapisan pertama menggunakan return_sequences=True untuk mengirim output ke lapisan berikutnya, sedangkan lapisan terakhir tidak mengembalikan urutan karena langsung terhubung ke lapisan output. Setiap lapisan LSTM diikuti oleh lapisan Dropout dengan rasio 0.2 guna mengurangi overfitting. Lapisan terakhir adalah Dense yang berfungsi sebagai output layer, diatur dengan units=4 untuk memprediksi empat nilai sekaligus. Model dikompilasi menggunakan optimizer Adam, dengan fungsi kerugian mean_squared_error dan metrik tambahan mean_absolute_error untuk mengevaluasi performa model secara lebih detail.
"""

from tensorflow.keras.layers import LSTM, Dropout, Dense

 #Membuat objek Sequential sebagai model
regressor = Sequential()

# Menambahkan lapisan LSTM pertama dengan 50 unit dan return_sequences=True untuk layer berantai
# Dropout digunakan untuk menghindari overfitting (mengabaikan 20% neuron secara acak selama training)
regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
regressor.add(Dropout(0.2))

# LSTM layer ke-2
regressor.add(LSTM(units=50, return_sequences=True))
regressor.add(Dropout(0.2))

# LSTM layer ke-3
regressor.add(LSTM(units=50, return_sequences=True))
regressor.add(Dropout(0.2))

# LSTM layer ke-4 (terakhir), return_sequences=False karena tidak ada lagi LSTM setelah ini
regressor.add(LSTM(units=50))
regressor.add(Dropout(0.2))

# Output layer - Dense, units=4 jika kamu ingin prediksi 4 langkah ke depan
# Jika hanya 1 langkah (misalnya harga close keesokan hari), ubah jadi units=1
regressor.add(Dense(units=4))

# Kompilasi model dengan optimizer Adam dan loss fungsi MSE (Mean Squared Error)
# Ditambahkan juga metric MAE untuk melihat performa lebih jelas
regressor.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])

# Melihat ringkasan arsitektur model
print(regressor.summary())

history = regressor.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_data=(X_test, y_test),
    verbose=1
)

"""## Evaluasi dan Visualisasi

Membuat prediksi menggunakan model LSTM (regressor) terhadap data pengujian (X_test). Hasil prediksi disimpan dalam variabel test_predicted, dan kemudian ditampilkan 5 hasil prediksi pertama.
"""

#membuat prediksi berdasarkan data pengujian (test data) 5 data pertama
test_predicted = regressor.predict(X_test)
test_predicted[:5]

"""Dari Hasil diatas Kolom pertama adalah high_predicted, low_predicted, open_predicted, close_predicted"""

# mengambil data hasil prediksi yang telah disesuaikan dengan scaling dan mengembalikannya ke dalam skala aslinya
test_inverse_predicted = MMS.inverse_transform(test_predicted) # inversing scaling predidksi data
test_inverse_predicted[:5]

"""Dari Hasil diatas Kolom pertama adalah high_predicted, low_predicted, open_predicted, close_predicted"""

#menggabungkan (merge) dua set data menggunakan perpustakaan Pandas (pandas.concat).

merge_data = pd.concat([df_scaled.iloc[-221:].copy(),pd.DataFrame(test_inverse_predicted,columns=['high_predicted','low_predicted','open_predicted','close_predicted'],index=df_scaled.iloc[-221:].index)], axis=1)

# memungkinkan  untuk membandingkan prediksi dengan data historis dengan lebih mudah dalam konteks skala aslinya
merge_data[['high','low','open_price','close']] = MMS.inverse_transform(merge_data[['high','low','open_price','close']]) # Inverse scaling

merge_data.head() #mengetahui beberapa barus pertama dari dataframe

"""DataFrame merge_data yang ditampilkan berisi gabungan antara data harga historis asli dan hasil prediksi model, yang sudah dikembalikan ke skala harga sebenarnya (melalui inverse scaling). Setiap baris mewakili satu tanggal tertentu, dan setiap kolom memiliki arti sebagai berikut:
*   date: tanggal data tersebut dicatat.
*   open_price, high, low, close: nilai aktual harga pembukaan, harga tertinggi, harga terendah, dan harga penutupan pada hari tersebut.
*   open_predicted, high_predicted, low_predicted, close_predicted: nilai hasil prediksi model untuk harga pembukaan, tertinggi, terendah, dan penutupan pada tanggal yang sama.

Dengan adanya dua set nilai (aktual dan prediksi), DataFrame ini memudahkan kita untuk mengevaluasi performa model, misalnya dengan menghitung error atau melakukan visualisasi perbandingan antara harga aktual dan prediksi.

##Visualisasi Actual Price dan Prediction Price
"""

# Pastikan kolom 'date' jadi index (datetime), jika belum
merge_data['date'] = pd.to_datetime(merge_data['date'])
merge_data.set_index('date', inplace=True)

# Plotting
fig, ax = plt.subplots(figsize=(12, 6))
ax.plot(merge_data['close'], label='Harga Aktual', color='blue', linestyle='dashed')
ax.plot(merge_data['close_predicted'], label='Harga Prediksi', color='orange')

# Format tampilan
ax.set_title('Perbandingan Harga Tertinggi Aktual vs Prediksi', fontsize=15)
ax.set_xlabel('Tanggal', fontsize=12)
ax.set_ylabel('Harga Saham', fontsize=12)
plt.xticks(rotation=45)
ax.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""##Evaluasi Model MSE, RMSE, R2 SCORE"""

from sklearn.metrics import mean_squared_error, r2_score

# Menghitung Mean Squared Error (MSE)
mse = mean_squared_error(y_test, test_predicted)
print("Mean Squared Error (MSE):", mse)

# Menghitung Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)
print("Root Mean Squared Error (RMSE):", rmse)

# Menghitung R-squared (R2) score
r2 = r2_score(y_test, test_predicted)
print("R-squared (R2) Score:", r2)

"""Evaluasi model menggunakan tiga metrik yaitu Mean Squared Error (MSE), Root Mean Squared Error (RMSE), dan R-squared (R²) Score memberikan gambaran tentang seberapa baik model memprediksi harga:
*   MSE (0.0012) menunjukkan rata-rata kuadrat selisih antara nilai aktual dan nilai prediksi. Nilai yang kecil mengindikasikan bahwa prediksi model cukup dekat dengan data asli.
*   RMSE (0.0347) merupakan akar dari MSE, yang menyatakan rata-rata kesalahan dalam satuan aslinya (misalnya harga dalam ribuan rupiah). Nilai ini juga tergolong kecil, artinya prediksi tidak jauh menyimpang.
*   R² Score (0.9008) mengukur seberapa baik variasi dalam data bisa dijelaskan oleh model. Nilai mendekati 1 (maksimal) berarti model sangat baik dalam menjelaskan variasi data.

Kesimpulan: Model LSTM yang digunakan memiliki performa prediksi yang baik, dengan error yang kecil dan tingkat penjelasan yang tinggi terhadap data aktual (R² = 90%). Artinya, model ini mampu memprediksi pergerakan harga dengan akurasi yang cukup tinggi.



"""